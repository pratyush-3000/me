{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratyush-3000/me/blob/master/Pratyush_Lahane_ML__Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this assignment is to acquaint oneself with the Random Forest concept and gain practical experience in training both regression and classification RF models."
      ],
      "metadata": {
        "id": "2__QNVdY0AZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 01"
      ],
      "metadata": {
        "id": "h7EzwM8J0AOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem you are going to work with \"Life Expectancy Data.csv\" dataset. <br>\n",
        "Import the dataset and\n",
        "1. Drop all the missing values from the dataset at the beginning of the project.\n",
        "2. Drop the \"Country\" column from the dataset.\n",
        "3. Split the dataset into train and test (consider 10% of data as the test).\n",
        "4. Prepare the datasets using pipeline."
      ],
      "metadata": {
        "id": "o9lq0iF30AfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "df = pd.read_csv('Life Expectancy Data.csv')\n",
        "df = df.dropna()\n",
        "\n",
        "life_expectancy_data_cleaned = df.dropna()\n",
        "\n",
        "life_expectancy_data_cleaned = life_expectancy_data_cleaned.drop(columns=[\"Country\"])\n",
        "\n",
        "train_data, test_data = train_test_split(life_expectancy_data_cleaned, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train = train_data.drop(columns=['Life expectancy'])\n",
        "y_train = train_data['Life expectancy']\n",
        "X_test = test_data.drop(columns=['Life expectancy'])\n",
        "y_test = test_data['Life expectancy']\n",
        "\n",
        "numeric_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor)\n",
        "])\n",
        "\n",
        "X_train_prepared = pipeline.fit_transform(X_train)\n",
        "X_test_prepared = pipeline.transform(X_test)\n",
        "\n",
        "print(\"Shape of X_train_prepared:\", X_train_prepared.shape)\n",
        "print(\"Shape of X_test_prepared:\", X_test_prepared.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCVgdPA1jAAj",
        "outputId": "2df8c163-8daf-451c-c2cd-381e99850569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_prepared: (1884, 19)\n",
            "Shape of X_test_prepared: (210, 19)\n",
            "Shape of y_train: (1884,)\n",
            "Shape of y_test: (210,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training and testing**"
      ],
      "metadata": {
        "id": "SLcVHxV60Aim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Train a Random Forest model with 500 trees on the prepared train dataset.\n",
        "2. Test your model on both train and test dataset and calculate RMSEs.\n",
        "3. Extract the feature importance of all the features in the prepared dataset."
      ],
      "metadata": {
        "id": "pKaFXWJZ1pvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "rf_model.fit(X_train_prepared, y_train)\n",
        "\n",
        "x_train_pred = rf_model.predict(X_train_prepared)\n",
        "y_test_pred = rf_model.predict(X_test_prepared)\n",
        "\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, x_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "feature_importances  = rf_model.feature_importances_\n",
        "\n",
        "feature_names = list(numeric_features) + list(pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out())\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "{\n",
        "    \"Train RMSE\": train_rmse,\n",
        "    \"Test RMSE\": test_rmse,\n",
        "    \"Feature Importances\": feature_importances_df\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyZB2VAzppF8",
        "outputId": "f415fcee-1413-4226-ffc4-95ff70b03fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Train RMSE': 0.6698125339503145,\n",
              " 'Test RMSE': 1.8536320250742764,\n",
              " 'Feature Importances':                             Feature  Importance\n",
              " 15  Income composition of resources    0.536204\n",
              " 10                         HIV/AIDS    0.299262\n",
              " 1                   Adult Mortality    0.087609\n",
              " 5                               BMI    0.013928\n",
              " 16                        Schooling    0.008019\n",
              " 8                 Total expenditure    0.007832\n",
              " 14               thinness 5-9 years    0.007299\n",
              " 3                           Alcohol    0.006335\n",
              " 0                              Year    0.005649\n",
              " 6                 under-five deaths    0.004248\n",
              " 7                             Polio    0.003876\n",
              " 13             thinness  1-19 years    0.003717\n",
              " 11                              GDP    0.003474\n",
              " 9                        Diphtheria    0.003453\n",
              " 12                       Population    0.003072\n",
              " 4            percentage expenditure    0.002999\n",
              " 2                     infant deaths    0.002819\n",
              " 17                 Status_Developed    0.000108\n",
              " 18                Status_Developing    0.000098}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 02"
      ],
      "metadata": {
        "id": "j8I9fpA02naQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem you are going to work with \"water_potability.csv\" dataset. <br>\n",
        "Import the dataset and\n",
        "\n",
        "1. Split the data into train and test datasets; consider 10% of data as the test set.\n",
        "2. Prepare the datasets using pipeline."
      ],
      "metadata": {
        "id": "0IEOamEJ2qFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
        "\n",
        "df = pd.read_csv('water_potability.csv')\n",
        "\n",
        "x = df.drop(columns=['Potability'])\n",
        "y = df['Potability']\n",
        "\n",
        "x__train, x_test, y_test , y_train = train_test_split(x, y , test_size=0.1, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "x_train_prepared = pipeline.fit_transform(x__train)\n",
        "x_test_prepared = pipeline.transform(x_test)\n",
        "\n",
        "x_train_prepared.shape , x_test_prepared.shape , y_train.shape , y_test.shape\n"
      ],
      "metadata": {
        "id": "7yh6zdv-GOUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f015fb3-318e-498d-e84a-8060527ed0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2948, 9), (328, 9), (328,), (2948,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training and testing**"
      ],
      "metadata": {
        "id": "6JqJyuc43I-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Train a Random Forest model with 500 trees on the prepared train dataset.\n",
        "2. Test your model on both train and test dataset and calculate precision and recall score and extract confusion matrix.\n",
        "3. Extract the feature importance of all the features in the prepared dataset."
      ],
      "metadata": {
        "id": "ue4lnwcV3s7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Correct the variable assignment in train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# The rest of the code remains the same\n",
        "from sklearn.ensemble import RandomForestClassifier # Changed to Classifier\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Correct the variable assignment in train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# The rest of the code remains the same\n",
        "model = RandomForestClassifier(n_estimators=500, random_state=42) # Changed to Classifier\n",
        "model.fit(x_train_prepared, y_train)\n",
        "\n",
        "y_train_pred = model.predict(x_train_prepared)\n",
        "y_test_pred = model.predict(x_test_prepared)\n",
        "\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "\n",
        "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
        "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "features_names = x.columns\n",
        "\n",
        "importances_df = pd.DataFrame({\n",
        "    'Feature': features_names,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(importances_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGTitrhkbXdx",
        "outputId": "e1af6782-2d3b-4c40-8fec-94c7e7df5f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Feature  Importance\n",
            "0               ph    0.128606\n",
            "4          Sulfate    0.124403\n",
            "1         Hardness    0.120700\n",
            "3      Chloramines    0.115204\n",
            "2           Solids    0.113521\n",
            "6   Organic_carbon    0.101080\n",
            "5     Conductivity    0.100899\n",
            "7  Trihalomethanes    0.097986\n",
            "8        Turbidity    0.097601\n"
          ]
        }
      ]
    }
  ]
}