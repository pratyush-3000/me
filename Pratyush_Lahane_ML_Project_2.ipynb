{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratyush-3000/me/blob/master/Pratyush_Lahane_ML_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this assignment is to acquaint oneself with the Decision Tree concept and gain practical experience in training both regression and classification DT models."
      ],
      "metadata": {
        "id": "2__QNVdY0AZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 01"
      ],
      "metadata": {
        "id": "h7EzwM8J0AOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem you are going to work with \"Life Expectancy Data.csv\" dataset. <br>\n",
        "Import the dataset and\n",
        "1. Drop all the missing values from the dataset at the beginning of the project.\n",
        "2. Drop the \"Country\" column from the dataset.\n",
        "3. Split the dataset into train and test (consider 10% of data as the test).\n",
        "4. Prepare the datasets using pipeline."
      ],
      "metadata": {
        "id": "o9lq0iF30AfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "df = pd.read_csv(\"Life Expectancy Data.csv\")\n",
        "\n",
        "x_cleaned = df.dropna()\n",
        "\n",
        "x_cleaned = x_cleaned.drop(columns = [\"Country\"])\n",
        "\n",
        "train_data , test_data = train_test_split(x_cleaned , test_size = 0.1 , random_state = 42)\n",
        "\n",
        "x_train = train_data.drop(columns = [\"Life expectancy\"])\n",
        "y_train = train_data[\"Life expectancy\"]\n",
        "\n",
        "x_test = test_data.drop(columns = [\"Life expectancy\"])\n",
        "y_test = test_data[\"Life expectancy\"]\n",
        "\n",
        "cat_columns = [\"Status\"]\n",
        "\n",
        "x_train_encoded = pd.get_dummies(x_train , columns = cat_columns)\n",
        "\n",
        "x_test_encoded = pd.get_dummies(x_test , columns = cat_columns)\n",
        "\n",
        "pipeline = Pipeline ([\n",
        "    (\"imputer\", SimpleImputer(strategy = \"median\")),\n",
        "    (\"scaler\" , StandardScaler())\n",
        "])\n",
        "\n",
        "x_train_transformed = pipeline.fit_transform(x_train_encoded)\n",
        "x_test_transformed = pipeline.transform(x_test_encoded)\n",
        "\n",
        "print(x_train_transformed)\n",
        "print(x_test_transformed)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZnlisSEteuv",
        "outputId": "eef46fe3-e876-4599-addd-4606c4260f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.94178494  2.06422426  0.27248116 ... -1.16393495 -0.47850059\n",
            "   0.47850059]\n",
            " [ 0.21427632  0.15837984  0.80483722 ... -0.08837411 -0.47850059\n",
            "   0.47850059]\n",
            " [-1.17299719  1.27268404 -0.23148258 ... -1.16393495 -0.47850059\n",
            "   0.47850059]\n",
            " ...\n",
            " [-0.71057268 -1.1096215  -0.25277683 ...  1.32522014  2.08986157\n",
            "  -2.08986157]\n",
            " [-0.47936043  0.81159264 -0.23858066 ... -0.0576438  -0.47850059\n",
            "   0.47850059]\n",
            " [ 0.21427632 -0.02605672 -0.24567874 ...  1.01791704  2.08986157\n",
            "  -2.08986157]]\n",
            "[[-1.63542169  2.80197049 -0.04693248 ... -1.6248896  -0.47850059\n",
            "   0.47850059]\n",
            " [ 0.44548857  0.32744668  0.11632338 ... -1.07174402 -0.47850059\n",
            "   0.47850059]\n",
            " [ 0.21427632 -0.07216586 -0.2243845  ... -0.27275597 -0.47850059\n",
            "   0.47850059]\n",
            " ...\n",
            " [ 1.37033758 -0.15669928 -0.23148258 ...  0.09600775 -0.47850059\n",
            "   0.47850059]\n",
            " [-0.24814818  2.04116969  0.30087348 ... -1.25612588 -0.47850059\n",
            "   0.47850059]\n",
            " [ 0.21427632 -0.54094211 -0.25277683 ...  0.34185023 -0.47850059\n",
            "   0.47850059]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training and testing**"
      ],
      "metadata": {
        "id": "SLcVHxV60Aim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to train three models (all decision tree); follow the following instructions:\n",
        "1. Train a decision tree model on the prepared train dataset with max_depth=2.\n",
        "> *   The purpose of training this model is to get familiar with decision tree model visualization; so, **DO NOT** test this model at all.\n",
        "> *   Use \"graphviz\" and \"source\" to visualize this model (plot the tree).\n",
        "\n",
        "2. Train a decision tree model on the prepared train dataset with max_depth=20.\n",
        "> *   Test the model on the train dataset and calculate RMSE.\n",
        "> *   Test the model on the test dataset and calculate RMSE.\n",
        "\n",
        "\n",
        "3. As you saw in the previous model, training a model with max_depth=20 will result in overfitting problem. To address the problem, train a new decision tree model and change max_depth manually until you solve the overfitting problem.\n",
        "> *   Test the model on the train dataset and calculate RMSE.\n",
        "> *   Test the model on the test dataset and calculate RMSE."
      ],
      "metadata": {
        "id": "pKaFXWJZ1pvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(max_depth = 2)\n",
        "tree_reg.fit(x_train_transformed , y_train)\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree_reg,\n",
        "    out_file = None,\n",
        "    feature_names = x_train_encoded.columns)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"Desicion Tree\", format = \"png\", cleanup = True)\n",
        "\n",
        "tree_reg_20 = DecisionTreeRegressor(max_depth = 20)\n",
        "tree_reg_20.fit(x_train_transformed , y_train)\n",
        "\n",
        "train_preds_depth_20 = tree_reg_20.predict(x_train_transformed)\n",
        "test_preds_depth_20 = tree_reg_20.predict(x_test_transformed)\n",
        "train_rsme_depth_20 = np.sqrt(mean_squared_error(y_train , train_preds_depth_20))\n",
        "test_rsme_depth_20 = np.sqrt(mean_squared_error(y_test , test_preds_depth_20))\n",
        "\n",
        "best_test_rsme = None\n",
        "best_max_depth = None\n",
        "best_train_rsme = None\n",
        "best_test_rsme = None\n",
        "\n",
        "for depth in range(1,21):\n",
        "  model = DecisionTreeRegressor(max_depth = depth)\n",
        "  model.fit(x_train_transformed , y_train)\n",
        "  train_preds = model.predict(x_train_transformed)\n",
        "  test_preds = model.predict(x_test_transformed)\n",
        "  train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
        "\n",
        "\n",
        "if best_test_rsme is None or test_rsme < best_test_rsme:\n",
        "   best_depth = depth\n",
        "   best_train_rmse =train_rmse\n",
        "   best_train_rsme = test_rmse\n",
        "\n",
        "train_rsme_depth_20, test_rsme_depth_20, best_depth , best_train_rmse , best_test_rsme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP0Oz0VdyXVj",
        "outputId": "8e8c50e2-dbc4-45e0-d168-5c127631fb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.04925026821469577, 2.5314132238836295, 20, 0.04925026821469577, None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 02"
      ],
      "metadata": {
        "id": "j8I9fpA02naQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem you are going to work with \"water_potability.csv\" dataset. <br>\n",
        "Import the dataset and\n",
        "\n",
        "1. Split the data into train and test datasets; consider 10% of data as the test set.\n",
        "2. Prepare the datasets using pipeline."
      ],
      "metadata": {
        "id": "0IEOamEJ2qFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "df = pd.read_csv(\"water_potability.csv\")\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "x_train = train_data.drop(columns=[\"Potability\"])\n",
        "y_train = train_data[\"Potability\"]\n",
        "\n",
        "x_test = test_data.drop(columns=[\"Potability\"])\n",
        "y_test = test_data[\"Potability\"]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "x_train_transformed = pipeline.fit_transform(x_train)\n",
        "x_test_transformed = pipeline.transform(x_test)\n",
        "\n",
        "x_train_transformed.shape, x_test_transformed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5ZkuYo89DAt",
        "outputId": "f624c05c-0cff-4577-a695-e48c16ca0311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2948, 9), (328, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training and testing**"
      ],
      "metadata": {
        "id": "6JqJyuc43I-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to train two models (all decision tree); follow the following instructions:\n",
        "1. Train a decision tree model on the prepared train dataset with max_depth=2.\n",
        "> *   The purpose of training this model is to get familiar with decision tree model visualization; so, **DO NOT** test this model at all.\n",
        "> *   Use \"graphviz\" and \"source\" to visualize this model (plot the tree).\n",
        "\n",
        "2. Train a decision tree model on the prepared train dataset with max_depth=20.\n",
        "> *   Test the model on the train dataset and extract confusion matrix and calculate precision and recall scores.\n",
        "> *   Test the model on the test dataset and extract confusion matrix and calculate precision and recall scores."
      ],
      "metadata": {
        "id": "ue4lnwcV3s7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "import graphviz\n",
        "\n",
        "# Step 1: Train Decision Tree model with max_depth=2\n",
        "model_depth_2 = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "model_depth_2.fit(x_train_transformed, y_train)\n",
        "\n",
        "\n",
        "dot_data = export_graphviz(model_depth_2, out_file=None, feature_names=x_train.columns,\n",
        "                           class_names=[\"Not Potable\", \"Potable\"], filled=True, rounded=True, special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"DecisionTree_max_depth_2\", format=\"png\", cleanup=True)\n",
        "\n",
        "model_depth_20 = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
        "model_depth_20.fit(x_train_transformed, y_train)\n",
        "\n",
        "\n",
        "train_preds_depth_20 = model_depth_20.predict(x_train_transformed)\n",
        "train_conf_matrix = confusion_matrix(y_train, train_preds_depth_20)\n",
        "train_precision = precision_score(y_train, train_preds_depth_20, average='binary', pos_label=1)\n",
        "train_recall = recall_score(y_train, train_preds_depth_20, average='binary', pos_label=1)\n",
        "\n",
        "\n",
        "test_preds_depth_20 = model_depth_20.predict(x_test_transformed)\n",
        "test_conf_matrix = confusion_matrix(y_test, test_preds_depth_20)\n",
        "test_precision = precision_score(y_test, test_preds_depth_20, average='binary', pos_label=1)\n",
        "test_recall = recall_score(y_test, test_preds_depth_20, average='binary', pos_label=1)\n",
        "\n",
        "train_conf_matrix, train_precision, train_recall, test_conf_matrix, test_precision, test_recall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4b_7ZJqCGMJ",
        "outputId": "164d9499-1e3b-4ab5-e359-5a8a254e977c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1782,   12],\n",
              "        [  77, 1077]]),\n",
              " 0.9889807162534435,\n",
              " 0.9332755632582322,\n",
              " array([[145,  59],\n",
              "        [ 72,  52]]),\n",
              " 0.46846846846846846,\n",
              " 0.41935483870967744)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}